
@inproceedings{volske_tldr_2017,
	address = {Copenhagen, Denmark},
	title = {{TL};{DR}: {Mining} {Reddit} to {Learn} {Automatic} {Summarization}},
	shorttitle = {{TL};{DR}},
	url = {http://aclweb.org/anthology/W17-4508},
	doi = {10.18653/v1/W17-4508},
	language = {en},
	urldate = {2023-04-19},
	booktitle = {Proceedings of the {Workshop} on {New} {Frontiers} in {Summarization}},
	publisher = {Association for Computational Linguistics},
	author = {Völske, Michael and Potthast, Martin and Syed, Shahbaz and Stein, Benno},
	year = {2017},
	pages = {59--63},
}

@article{kowsari_text_2019,
	title = {Text {Classification} {Algorithms}: {A} {Survey}},
	volume = {10},
	issn = {2078-2489},
	shorttitle = {Text {Classification} {Algorithms}},
	url = {https://www.mdpi.com/2078-2489/10/4/150},
	doi = {10.3390/info10040150},
	abstract = {In recent years, there has been an exponential growth in the number of complex documentsand texts that require a deeper understanding of machine learning methods to be able to accuratelyclassify texts in many applications. Many machine learning approaches have achieved surpassingresults in natural language processing. The success of these learning algorithms relies on their capacityto understand complex models and non-linear relationships within data. However, finding suitablestructures, architectures, and techniques for text classification is a challenge for researchers. In thispaper, a brief overview of text classification algorithms is discussed. This overview covers differenttext feature extractions, dimensionality reduction methods, existing algorithms and techniques, andevaluations methods. Finally, the limitations of each technique and their application in real-worldproblems are discussed.},
	language = {en},
	number = {4},
	urldate = {2023-04-23},
	journal = {Information},
	author = {{Kowsari} and {Jafari Meimandi} and {Heidarysafa} and {Mendu} and {Barnes} and {Brown}},
	month = apr,
	year = {2019},
	pages = {150},
}


@article{vijayarani_text_2016,
	title = {Text {Mining}: open {Source} {Tokenization} {Tools} – {An} {Analysis}},
	volume = {3},
	issn = {24543934},
	shorttitle = {Text {Mining}},
	url = {http://aircconline.com/acii/V3N1/3116acii04.pdf},
	doi = {10.5121/acii.2016.3104},
	number = {1},
	urldate = {2023-04-23},
	journal = {Advanced Computational Intelligence: An International Journal (ACII)},
	author = {Vijayarani, S and Janani, R},
	month = jan,
	year = {2016},
	pages = {37--47},
}


@article{shah_comparative_2020,
	title = {A {Comparative} {Analysis} of {Logistic} {Regression}, {Random} {Forest} and {KNN} {Models} for the {Text} {Classification}},
	volume = {5},
	issn = {2365-4317, 2365-4325},
	url = {http://link.springer.com/10.1007/s41133-020-00032-0},
	doi = {10.1007/s41133-020-00032-0},
	language = {en},
	number = {1},
	urldate = {2023-04-23},
	journal = {Augmented Human Research},
	author = {Shah, Kanish and Patel, Henil and Sanghvi, Devanshi and Shah, Manan},
	month = dec,
	year = {2020},
	pages = {12},
}


@article{xu_improved_2012,
	title = {An {Improved} {Random} {Forest} {Classifier} for {Text} {Categorization}},
	volume = {7},
	issn = {1796-203X},
	url = {http://ojs.academypublisher.com/index.php/jcp/article/view/6969},
	doi = {10.4304/jcp.7.12.2913-2920},
	number = {12},
	urldate = {2023-04-23},
	journal = {Journal of Computers},
	author = {Xu, Baoxun and Guo, Xiufeng and Ye, Yunming and Cheng, Jiefeng},
	month = dec,
	year = {2012},
	pages = {2913--2920},
}

@article{lecun_deep_2015,
	title = {Deep learning},
	volume = {521},
	issn = {0028-0836, 1476-4687},
	url = {http://www.nature.com/articles/nature14539},
	doi = {10.1038/nature14539},
	language = {en},
	number = {7553},
	urldate = {2023-04-23},
	journal = {Nature},
	author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
	month = may,
	year = {2015},
	pages = {436--444},
}


@article{singh_novel_2022,
	title = {A novel approach for dimension reduction using word embedding: {An} enhanced text classification approach},
	volume = {2},
	issn = {26670968},
	shorttitle = {A novel approach for dimension reduction using word embedding},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2667096822000052},
	doi = {10.1016/j.jjimei.2022.100061},
	language = {en},
	number = {1},
	urldate = {2023-04-23},
	journal = {International Journal of Information Management Data Insights},
	author = {Singh, Ksh. Nareshkumar and Devi, S. Dickeeta and Devi, H. Mamata and Mahanta, Anjana Kakoti},
	month = apr,
	year = {2022},
	pages = {100061},
}


@article{huang_using_2005,
	title = {Using {AUC} and accuracy in evaluating learning algorithms},
	volume = {17},
	issn = {1041-4347},
	url = {http://ieeexplore.ieee.org/document/1388242/},
	doi = {10.1109/TKDE.2005.50},
	number = {3},
	urldate = {2023-04-23},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Huang, Jin and Ling, C.X.},
	month = mar,
	year = {2005},
	pages = {299--310},
}


@book{james_introduction_2013,
	address = {New York, NY},
	series = {Springer {Texts} in {Statistics}},
	title = {An {Introduction} to {Statistical} {Learning}},
	volume = {103},
	isbn = {9781461471370 9781461471387},
	url = {http://link.springer.com/10.1007/978-1-4614-7138-7},
	urldate = {2023-04-24},
	publisher = {Springer New York},
	author = {James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert},
	year = {2013},
	doi = {10.1007/978-1-4614-7138-7},
}


@article{pedregosa_scikit-learn_2012,
	title = {Scikit-learn: {Machine} {Learning} in {Python}},
	copyright = {arXiv.org perpetual, non-exclusive license},
	shorttitle = {Scikit-learn},
	url = {https://arxiv.org/abs/1201.0490},
	doi = {10.48550/ARXIV.1201.0490},
	abstract = {Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language. Emphasis is put on ease of use, performance, documentation, and API consistency. It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings. Source code, binaries, and documentation can be downloaded from http://scikit-learn.org.},
	urldate = {2023-04-24},
	author = {Pedregosa, Fabian and Varoquaux, Gaël and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Müller, Andreas and Nothman, Joel and Louppe, Gilles and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and Vanderplas, Jake and Passos, Alexandre and Cournapeau, David and Brucher, Matthieu and Perrot, Matthieu and Duchesnay, Édouard},
	year = {2012},
	keywords = {FOS: Computer and information sciences, Machine Learning (cs.LG), Mathematical Software (cs.MS)},
}


@misc{reddit_inc_reddit_2023,
	title = {Reddit},
	url = {https://www.redditinc.com/},
	urldate = {2023-04-24},
	author = {{Reddit Inc.}},
	month = apr,
	year = {2023},
}
