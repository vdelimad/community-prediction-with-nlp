{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title-block-style: default\n",
    "title-block-banner: '#FF4500'\n",
    "title-block-banner-color: '#FFFFFF'\n",
    "title-block-categories: true\n",
    "title: Community Prediction with NLP\n",
    "subtitle: Text Classification Algorithms Using Reddit Data\n",
    "author-title: AUTHORS\n",
    "author:\n",
    "  - name: Victor De Lima<br>Matthew Moriarty\n",
    "    affiliations:\n",
    "      - name: Georgetown University<br>M.S. Data Science and Analytics\n",
    "format:\n",
    "  html:\n",
    "    toc: true\n",
    "    embed-resources: true\n",
    "    toc-title: Contents\n",
    "    code-fold: true\n",
    "    code-summary: Show Code\n",
    "    bibliography: references.bib\n",
    "    grid:\n",
    "      sidebar-width: 0px\n",
    "      body-width: 1000px\n",
    "      margin-width: 200px\n",
    "    theme:\n",
    "      - journal # flatly, sketchy (playbook feel)\n",
    "      - custom.scss\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Natural language is one of the purest and most complex forms of data in the world. Within each of the numerous written languages across the globe are even more intricacies, such as grammatical structures, idioms, and slang terms. These components combine to form a complex yet profoundly intriguing data structure known to us all.\n",
    "\n",
    "A popular place for such natural languages is Reddit. Here, registered users submit content such as links, text posts, images, and videos, which other members then vote up or down. Subreddits, smaller communities within Reddit, house content associated with a specific topic. Since these topics differ, analyzing whether these subreddits use different natural language components is intriguing. Our goal is to analyze whether we can take an anonymous Reddit post, perform an analysis on the natural language comprising that post, and correctly assign it to the subreddit to which it belongs.\n",
    "\n",
    "Our analysis is motivated by the beneficial applications of Natural Language Processing (NLP) in the real world. For instance, email companies can use NLP to filter out spam emails for their users. Likewise, social networking companies can use NLP to identify commonalities between sub-communities. Our analysis provides a glimpse into the power of NLP tasks and paves the way for more impactful and relevant applications of NLP in the real world.\n",
    "\n",
    "## About the Data\n",
    "\n",
    "Our data set, obtained from Völske et al. (2017) [@volske_tldr_2017], contains nearly 19 GB of data, involving almost four million Reddit posts. Alongside each post is a collection of information, such as the author of the post and the subreddit to which the post belongs. As a data reduction technique, we randomly sampled 40,000 posts from each of the five most popular subreddits, for a total of 200,000 posts, providing us with a data set of size 300 MB.\n",
    "\n",
    "Since the Reddit posts are raw and untouched, we apply a series of cleaning steps to the content of each post. These include the following:\n",
    "\n",
    "* Removing punctuation and special characters\n",
    "* Stemming and Lemmatization\n",
    "\n",
    "Having cleaned the textual data comprising each Reddit post, we obtained a vocabulary of over 245,000 unique words used across all posts. We kept only the 5,000 most common words as a variable selection technique. In doing so, we can efficiently remove almost 98% of unique words while maintaining nearly 95% of the total words used (see Figure 1 below).\n",
    "\n",
    "## Methodologies\n",
    "\n",
    "### Binary Classification\n",
    "\n",
    "First, we explore binary classification. The logistic regression model estimates the probability that the dependent variable Y belongs to a particular category rather than modeling the direct response as in linear regression. The model uses the maximum likelihood method for model fitting, which estimates the beta coefficients that maximize the likelihood function (James et al. 2013). This study uses the SKLearn implementation of logistic regression (Pedregosa et al. 2012), including a Lasso penalty term. We ran the model using a regularization lambda of 0.001 and five-fold Cross-Validation (CV) on the 'AskReddit' vs 'timu' and ‘leagueoflegends’ vs ‘trees’ categories. Figure 2 shows the model results. Although this is a relatively good performance, many real-world scenarios are not binary, for which more complex models are necessary.\n",
    "\n",
    "### Multi-Class Classification\n",
    "\n",
    "**Baseline Model**. Our baseline model for comparison takes a random guess as to which subreddit a post belongs. We can expect this model to be around 20% accurate, correctly classifying approximately one in five posts. Key Design Choices: random uniform class probability assignment.\n",
    "\n",
    "**Decision Trees**. A decision tree is quite like how it sounds - it is a tree that makes decisions in order to categorize data. Starting from its \"root,\" the decision tree splits data based on certain conditions to create the purest splits possible. Key Design Choices: 5-Fold CV, maximum tree depth of 8. See Figure 3 for CV hyperparameter search.\n",
    "\n",
    "**Random Forest**. A random forest is an ensemble of simple trees known as weak learners. When constructing the random forest, each tree only considers a subset of the variables. This procedure decorrelates the trees, making the resulting trees' average less variable and more reliable. Key Design Choices: 5-Fold CV, maximum tree depth of 10. See Figure 3 for CV hyperparameter search.\n",
    "\n",
    "**Neural Networks**. In a basic neural network, the model feeds a vector of variables, referred to as the \"input layer,\" to a second layer that performs non-linear transformations of the data. This process may be repeated for additional layers until reaching the last output layer, providing the predicted values. The procedure optimizes iteratively using gradient descent and backpropagation algorithms. We implemented a deep feed-forward neural network using PyTorch and used grid search for hyperparameter tuning. Key Design Choices: 5-Fold CV, ReLU activation, 0.5 dropout rate, Lasso regulation, Adam Optimizer.\n",
    "\n",
    "## Results\n",
    "\n",
    "In order to evaluate our models, we train each model - with optimally-chosen hyperparameters - on a large training set, measuring its performance on a held-out test set. For this, we calculate the overall model accuracy on the classification task, weighted precision and recall measures, and the area under the Receiver Operating Characteristic (ROC) curve. Results are available in Table 1. Furthermore, confusion matrices for both the Baseline and Neural Network models can be seen in Figures 4a and 4b, respectively.\n",
    "\n",
    "It is evident by both Table 1 and Figure 4 that the Neural Network model outperforms all other models across all metrics. Achieving a classification accuracy of almost 85%, this model proves that it can effectively analyze natural language within a Reddit post in order to assign it to the correct subreddit. In Figure 4b specifically, this effectiveness is highlighted by the sharp diagonal line in the confusion matrix, indicating very strong classification accuracy, precision, and recall measures for the model. Although the Decision Tree and Random Forest models are outperformed by the Neural Network model, their vast improvement over the Baseline model indicate successes for both models in the realm of NLP. The words of highest overall relevance are shown in Figure 5.\n",
    "\n",
    "## Conclusions\n",
    "\n",
    "This study shows that the text-based language people use in discussions as part of a community contains enough information to predict the association effectively. Using Term Frequency methods and supervised learning algorithms, our model utilizes information on both words used and their usage frequency. We find the best-performing model to be the feed-forward neural network described in the experiment section, followed by the random forest, both significantly outperforming the random classifier. This research may prove valuable for companies that identify and appeal to individuals sharing common interests. Future research may involve recurrent neural networks, which have also been shown effective for text-based classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
